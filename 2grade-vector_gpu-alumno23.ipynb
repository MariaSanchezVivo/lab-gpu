{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23054356-23f1-4962-ad8a-31f634cdd71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "7.89 ms ± 76.5 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.4 ms ± 64.2 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.6 ms ± 25.6 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f0c96-ff9c-4578-a500-ba087b689b5a",
   "metadata": {},
   "source": [
    "a) Usando la librería Cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a164a3-5b9c-4d42-8af9-5111130ef0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo promedio GPU copiando desde CPU: 14.628 ms\n",
      "Tiempo promedio GPU arrays directos en GPU: 4.524 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# Constantes\n",
    "size = 5_000_000\n",
    "a, b, c = 3.5, 2.8, 10.0\n",
    "\n",
    "# Arrays en CPU\n",
    "x_cpu = np.random.rand(size).astype(np.float64)\n",
    "y_cpu = np.random.rand(size).astype(np.float64)\n",
    "z_cpu = a*x_cpu**2 + b*y_cpu + c\n",
    "\n",
    "# Caso 1: copiando desde CPU\n",
    "def grade2_cupy_copy(x, y, a, b, c):\n",
    "    x_gpu = cp.asarray(x)\n",
    "    y_gpu = cp.asarray(y)\n",
    "    return a*x_gpu**2 + b*y_gpu + c\n",
    "\n",
    "execution_copy = benchmark(grade2_cupy_copy, (x_cpu, y_cpu, a, b, c), n_repeat=10, n_warmup=2)\n",
    "gpu_avg_copy_ms = np.mean(execution_copy.gpu_times) * 1000 #milisegundos\n",
    "print(f\"Tiempo promedio GPU copiando desde CPU: {gpu_avg_copy_ms:.3f} ms\")\n",
    "\n",
    "# Caso 2: arrays ya en GPU\n",
    "x_gpu = cp.random.rand(size, dtype=cp.float64)\n",
    "y_gpu = cp.random.rand(size, dtype=cp.float64)\n",
    "\n",
    "def grade2_cupy_no_copy(x_gpu, y_gpu, a, b, c):\n",
    "    return a*x_gpu**2 + b*y_gpu + c\n",
    "\n",
    "execution_no_copy = benchmark(grade2_cupy_no_copy, (x_gpu, y_gpu, a, b, c), n_repeat=10, n_warmup=2)\n",
    "gpu_avg_no_copy_ms = np.mean(execution_no_copy.gpu_times) * 1000 #milisegundos\n",
    "print(f\"Tiempo promedio GPU arrays directos en GPU: {gpu_avg_no_copy_ms:.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833c6ba-2c44-467c-ab7d-271ee99015b5",
   "metadata": {},
   "source": [
    "b) Usando la librería Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff90d0f-d0ec-4001-bd82-df229cde9a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo promedio GPU copiando desde CPU: 2.450 ms\n",
      "Tiempo promedio GPU arrays directos en GPU: 2.321 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from numba import vectorize, float64\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# Constantes\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10.0\n",
    "size = 5_000_000\n",
    "\n",
    "# Crear la ufunc de Numba para GPU\n",
    "@vectorize([float64(float64, float64, float64, float64, float64)], target='cuda')\n",
    "def grade2_numba(x, y, a, b, c):\n",
    "    return a*x*x + b*y + c\n",
    "\n",
    "# Copiando datos desde CPU\n",
    "x_cpu = np.random.rand(size).astype(np.float64)\n",
    "y_cpu = np.random.rand(size).astype(np.float64)\n",
    "\n",
    "# Copiar manualmente a GPU para no contar el overhead en la medición\n",
    "x_gpu = cp.asarray(x_cpu)\n",
    "y_gpu = cp.asarray(y_cpu)\n",
    "z_gpu = cp.zeros_like(x_gpu)\n",
    "\n",
    "# Benchmark\n",
    "def run_copy():\n",
    "    z = grade2_numba(x_gpu, y_gpu, a, b, c)\n",
    "\n",
    "result_copy = benchmark(run_copy, n_repeat=10, n_warmup=2)\n",
    "gpu_avg_copy_ms = np.mean(result_copy.gpu_times) * 1000\n",
    "print(f\"Tiempo promedio GPU copiando desde CPU: {gpu_avg_copy_ms:.3f} ms\")\n",
    "\n",
    "# Arrays creados directamente en GPU\n",
    "x_gpu_direct = cp.random.rand(size, dtype=cp.float64)\n",
    "y_gpu_direct = cp.random.rand(size, dtype=cp.float64)\n",
    "z_gpu_direct = cp.zeros_like(x_gpu_direct)\n",
    "\n",
    "# Benchmark\n",
    "def run_direct():\n",
    "    z = grade2_numba(x_gpu_direct, y_gpu_direct, a, b, c)\n",
    "\n",
    "result_direct = benchmark(run_direct, n_repeat=10, n_warmup=2)\n",
    "gpu_avg_direct_ms = np.mean(result_direct.gpu_times) * 1000\n",
    "print(f\"Tiempo promedio GPU arrays directos en GPU: {gpu_avg_direct_ms:.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfdff3-681f-40f0-a9e1-44ceb036aac8",
   "metadata": {},
   "source": [
    "c) Los resultados muestran que la operación vectorizada (z = a x^2 + b y + c) se ejecuta muy rápidamente en GPU. Usando CuPy, copiar los arrays desde CPU introduce un overhead significativo, aumentando el tiempo de 4.524 ms (solo kernel) a 14.628 ms, mientras que al usar arrays ya en GPU el tiempo se reduce notablemente, mostrando que la GPU procesa la operación de manera eficiente. Usando Numba, la diferencia entre copiar desde CPU y usar arrays en GPU es mínima (2.450 ms y 2.321 ms;se sigue obteniendo un mayor tiempo debido al copiado) ya que la librería maneja automáticamente la transferencia de datos de manera optimizada y compila la función a código de bajo nivel. En general, la principal limitación en los tiempos totales es la transferencia de memoria desde la CPU, mientras que la ejecución de la función en GPU es prácticamente instantánea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
